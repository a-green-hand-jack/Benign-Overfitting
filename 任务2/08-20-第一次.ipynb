{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"LxgHeMVTm94u"},"source":["# 环境设置代码\n","在开始之前，我们需要运行一些样板代码来设置我们的环境。每次启动笔记本时，您都需要重新运行此设置代码。\n","\n","首先，运行此单元格来加载[autoreload](https://ipython.readthedocs.io/en/stable/config/extensions/autoreload.html?highlight=autoreload)扩展。这使得我们可以编辑`.py`源文件，并将其重新导入到笔记本中，以实现无缝的编辑和调试体验。"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1692713179803,"user":{"displayName":"Rose Zhao","userId":"00366990984783742567"},"user_tz":-480},"id":"Pl8VAh2pmXhn"},"outputs":[],"source":["%load_ext autoreload\n","%autoreload 2\n","%load_ext tensorboard"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"nYgOPzI3nQNC"},"source":["### Google Colab 设置\n","接下来，我们需要运行一些命令，在 Google Colab 上设置我们的环境。如果您正在本地计算机上运行此笔记本，则可以跳过此部分。\n","\n","运行以下单元格以挂载您的 Google Drive。点击链接，登录到您的 Google 帐户（与您用来存储此笔记本的帐户相同！），然后将授权代码复制到下面出现的文本框中。"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":34741,"status":"ok","timestamp":1692713214540,"user":{"displayName":"Rose Zhao","userId":"00366990984783742567"},"user_tz":-480},"id":"iG2KPQVKnRqe","outputId":"7477a7fc-b6d1-4497-c7ec-482893a096a5"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"O96kmMz3nmQC"},"source":["现在回想一下您将此笔记本上传到 Google Drive 上的路径，并在下面填写它。如果一切正常，运行以下单元格应该会打印出作业中的文件名：\n","\n","```\n","['08-20-第一次.ipynb', 'get_rank_cpu.py', 'get_rank_gpu.py', '__pycache__', 'mlp.py']\n","```"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1486,"status":"ok","timestamp":1692713216022,"user":{"displayName":"Rose Zhao","userId":"00366990984783742567"},"user_tz":-480},"id":"ctI9utDDnrEI","outputId":"e55d14b3-3d95-4e5b-cdfb-ef4799d91737"},"outputs":[],"source":["import os\n","\n","GOOGLE_DRIVE_PATH_AFTER_MYDRIVE = '我的笔记本电脑/任务2'\n","GOOGLE_DRIVE_PATH = os.path.join('drive', 'Othercomputers', GOOGLE_DRIVE_PATH_AFTER_MYDRIVE)\n","print(os.listdir(GOOGLE_DRIVE_PATH))"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"rPgtc_peoKkI"},"source":["一旦您成功挂载了 Google Drive 并找到了此作业的路径，运行以下单元格以使我们能够从此作业的 `.py` 文件中进行导入。如果它正常工作，它应该会打印出消息：\n","\n","```\n","Hello from get_rank.py!\n","```\n","\n","以及文件 `get_rank.py!` 的最后编辑时间。"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6453,"status":"ok","timestamp":1692713222471,"user":{"displayName":"Rose Zhao","userId":"00366990984783742567"},"user_tz":-480},"id":"IpUbG_NPr3Co","outputId":"f159ce2a-a2a4-4947-8431-2164227807f2"},"outputs":[],"source":["import sys\n","sys.path.append(GOOGLE_DRIVE_PATH)\n","\n","import time, os\n","os.environ[\"TZ\"] = \"US/Eastern\"\n","time.tzset()\n","\n","from get_rank_gpu import hello\n","hello()\n","\n","get_rank_gpu_path = os.path.join(GOOGLE_DRIVE_PATH, 'get_rank_gpu.py')\n","get_rank_gpu_path_edit_time = time.ctime(os.path.getmtime(get_rank_gpu_path))\n","print('get_rank_gpu.py last edited on %s' % get_rank_gpu_path_edit_time)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"sP2sVTPiAHpi"},"source":["# 观察原始情况"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"zi2T2gep6IMR"},"source":["### 验证rk和Rk的计算\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":596},"executionInfo":{"elapsed":136408,"status":"ok","timestamp":1692713358877,"user":{"displayName":"Rose Zhao","userId":"00366990984783742567"},"user_tz":-480},"id":"sFpowtvN-M10","outputId":"1516ed71-95cc-4be2-b0b5-885e59438b18"},"outputs":[],"source":["from get_rank_gpu import Effective_Ranks, get_Effective_Ranks, get_Effective_Ranks_GPU\n","import torch\n","import matplotlib.pyplot as plt\n","import torchvision\n","from torchvision.datasets import CIFAR10\n","from torchvision.transforms import ToTensor\n","import torchvision.transforms as transforms\n","import numpy as np\n","\n","# 创建一个get_Effective_Ranks_GPU实例，并将数据转移到GPU上\n","get_cifar10_gpu = get_Effective_Ranks_GPU(dataset_name='CIFAR10', path_to_dataset_folder='dataset_folder', my_transform=transforms.Compose([ToTensor(),]))\n","get_cifar10_gpu.convert_to_matrix()\n","get_cifar10_gpu.convert_to_rank()\n","get_cifar10_gpu.plot_vectors()\n","rk_1, Rk_2 = get_cifar10_gpu.train_rk, get_cifar10_gpu.train_Rk\n","print(rk_1, \"\\n\", Rk_2)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"D_IklDMZ5sEr"},"source":["### 建立MLP\n","\n","为了方便在以后的所有的代码块中的调用，提前定义好MLP"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IhT1Iud55w_Q"},"outputs":[],"source":["import torch.nn as nn\n","import torch.nn.functional as F\n","\n","''' MLP '''\n","class MLP(nn.Module):\n","    def __init__(self, channel=3, num_classes=10, im_size=(32, 32)):\n","        super(MLP, self).__init__()\n","        self.fc_1 = nn.Linear(im_size[0] * im_size[1]*channel, 128)\n","        self.fc_2 = nn.Linear(128, 128)\n","        self.fc_3 = nn.Linear(128, num_classes)\n","\n","    def forward(self, x):\n","        out = x.view(x.size(0), -1)\n","        out = F.relu(self.fc_1(out))\n","        out = F.relu(self.fc_2(out))\n","        out = self.fc_3(out)\n","        return out"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"dvsIncqSAX8C"},"source":["### 进行模型的训练\n","\n","为了简单起见，第一次训练不对图片进行任何额外的处理"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":89656,"status":"ok","timestamp":1692713448528,"user":{"displayName":"Rose Zhao","userId":"00366990984783742567"},"user_tz":-480},"id":"acGmaJyxAc6N","outputId":"afeca48f-88fc-4ba5-ee64-a010df4f59b0"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","from torchvision.transforms import ToTensor\n","import torch.optim as optim\n","import torchvision\n","import torchvision.transforms as transforms\n","import torch.nn.functional as F\n","from torch.utils.tensorboard import SummaryWriter\n","from get_rank_gpu import get_Effective_Ranks_GPU\n","\n","# 设置设备\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","# 添加tensorboard\n","writer = SummaryWriter(\"logs_train\")\n","\n","# 数据预处理,但是不在第一时间使用\n","CIFAR_MEAN = [0.49139968, 0.48215827, 0.44653124]\n","CIFAR_STD = [0.2023, 0.1994, 0.2010]\n","train_transform = transforms.Compose([\n","      transforms.RandomResizedCrop(size=(32, 32), scale=(0.8, 1.0)),  # 随机裁剪，但保持大小不变\n","      transforms.ToTensor(),\n","      transforms.Normalize(CIFAR_MEAN, CIFAR_STD)\n","    ])\n","\n","# 加载 CIFAR-10 数据集， 使用get_Effective_Ranks_GPU，同时计算协方差\n","get_cifar10_gpu_normal = get_Effective_Ranks_GPU(dataset_name='CIFAR10', path_to_dataset_folder='dataset_folder', my_transform=transforms.Compose([ToTensor(),]))\n","train_loader = get_cifar10_gpu_normal.build_dataloader()[0]\n","val_loader = get_cifar10_gpu_normal.build_dataloader()[1]\n","test_loader = get_cifar10_gpu_normal.build_dataloader()[2]\n","\n","# 得到对应的协方差\n","rk, Rk = get_cifar10_gpu_normal.train_rk, get_cifar10_gpu_normal.train_Rk\n","rk_max_value = max(rk)  # 找到列表中的最大值\n","rk_max_index = rk.index(rk_max_value)  # 找到最大值对应的索引\n","Rk_max_value = max(Rk)  # 找到列表中的最大值\n","Rk_max_index = Rk.index(Rk_max_value)  # 找到最大值对应的索引"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"LRA7PCbrm0uE"},"source":["暂时采用了```\n","momentum = 0.9\n","weight_decay = 0.0005\n","learning_rate = 0.01\n","batch_size = 512\n","num_epochs = 5```的超参数。同时以字典的形式保留训练好的网络，以方便在未来使用```model_vgg162 = torch.load(\"vgg16_method2.pth\")```的形式实现在其他文件或者代码块中完成对网络的读取。"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":46455,"status":"ok","timestamp":1692713981770,"user":{"displayName":"Rose Zhao","userId":"00366990984783742567"},"user_tz":-480},"id":"p-Zzn4yTOn0X","outputId":"d98dbafc-8e4f-43ac-8e1b-e9ae89e316a8"},"outputs":[],"source":["# 暂定的超参数\n","momentum = 0.9\n","weight_decay = 0.0005\n","learning_rate = 0.01\n","batch_size = 512\n","num_epochs = 5\n","\n","# 创建模型实例并将其移至 GPU\n","channel=3\n","num_classes=10\n","im_size=(32, 32)\n","model = MLP()\n","model.to(device)\n","\n","# 定义损失函数和优化器\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum, weight_decay=weight_decay)\n","\n","# 记录训练的次数\n","total_train_step = 0\n","# 记录训练过程中的准确率\n","correct = 0\n","total = 0\n","\n","# 训练循环\n","for epoch in range(num_epochs):\n","    print(\"------------第{}轮训练开始了-----------\".format(epoch + 1))\n","\n","    # 训练步骤开始\n","    for batch_idx, (imgs, targets) in enumerate(train_loader):\n","      # 将数据移至 GPU\n","        imgs, targets = imgs.to(device), targets.to(device)\n","        # imgs: 一个形状为 (batch_size, channels, height, width) 的张量\n","        # targets: 一个形状为 (batch_size,) 的张量，包含每张图像的标签\n","\n","        outputs = model(imgs)\n","        loss = criterion(outputs, targets)\n","\n","        # 计算准确率\n","        _, predicted = torch.max(outputs, 1)\n","        total += targets.size(0)\n","        correct += (predicted == targets).sum().item()\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        total_train_step = epoch * len(train_loader) + batch_idx + 1\n","        if total_train_step % 100 == 0:\n","            acc = correct / total\n","            print(\"训练次数{}时，损失值是{}，准确率是{:.2f}%\".format(total_train_step, loss, acc * 100))\n","            writer.add_scalar(\"train_loss\", loss.item(), total_train_step)\n","            writer.add_scalar(\"train_accuracy\", acc, total_train_step)\n","          # 更新模型权重并记录到Tensorboard\n","    for name, param in model.named_parameters():\n","        writer.add_histogram(name, param.clone().cpu().data.numpy(), epoch)\n","print(\"Training finished.\")\n","writer.close()     #将event log写完之后，记得close()\n","# 在训练循环结束后\n","torch.save(model.state_dict(), 'model_normal.pth')\n","print(\"模型参数已保存为model_normal.pth\")\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"3T3wOeaqn4jk"},"source":["现在，已经完成了第一次，没有任何**增强**的网络的训练。然后我们用这个网络在Vail上进行验证，为了寻求好的**超参数**，目前这包括两个部分：\n","\n","1. ```momentum = 0.9, weight_decay = 0.0005, learning_rate = 0.01, batch_size = 512, num_epochs = 5```\n","这些用在优化器```optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum, weight_decay=weight_decay)```上的参数\n","\n","2. ```\n","    CIFAR_MEAN = [0.49139968, 0.48215827, 0.44653124]\n","    CIFAR_STD = [0.2023, 0.1994, 0.2010]\n","    train_transform = transforms.Compose([transforms.RandomResizedCrop(size=(32, 32), scale=(0.8, 1.0)),transforms.ToTensor(),transforms.Normalize(CIFAR_MEAN, CIFAR_STD)])\n","  ```\n","    也就是我们关注的对图片的**增强**\n","\n","我们不可以直接在test上计算loss和准确率，所以把train的10%分割作为vail集，并在它上面寻找合适的超参数。"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3182,"status":"ok","timestamp":1692716286526,"user":{"displayName":"Rose Zhao","userId":"00366990984783742567"},"user_tz":-480},"id":"vWzaGmbFqjGC","outputId":"9d4c710b-d622-4f49-e129-56dc1f29f5fa"},"outputs":[],"source":["# 验证步骤开始\n","for batch_idx, (imgs, targets) in enumerate(val_loader):\n","  # 将数据移至 GPU\n","    imgs, targets = imgs.to(device), targets.to(device)\n","    # imgs: 一个形状为 (batch_size, channels, height, width) 的张量\n","    # targets: 一个形状为 (batch_size,) 的张量，包含每张图像的标签\n","\n","    outputs = model(imgs)\n","    loss = criterion(outputs, targets)\n","\n","    # 计算准确率\n","    _, predicted = torch.max(outputs, 1)\n","    total += targets.size(0)\n","    correct += (predicted == targets).sum().item()\n","\n","    total_train_step = batch_idx + 1\n","    if total_train_step % 100 == 0:\n","        acc = correct / total\n","        print(\"测试第{}图片时，损失值是{}，准确率是{:.2f}%\".format(total_train_step, loss, acc * 100))\n","        writer.add_scalar(\"val_loss\", loss.item(), total_train_step)\n","        writer.add_scalar(\"val_accuracy\", acc, total_train_step)\n","print(\"Valing finished.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":912,"status":"ok","timestamp":1692716293766,"user":{"displayName":"Rose Zhao","userId":"00366990984783742567"},"user_tz":-480},"id":"pHsWLFeQtEUP","outputId":"18a5eb5c-db1b-4aed-daee-85eae57f04fe"},"outputs":[],"source":["nomraml_dict = {\"协方差最大值\":rk_max_value, \"协方差最大值对应的索引\":rk_max_index, \"训练的模型的保留路径\":\"model_normal.pth\",\"在测试集中的损失\":loss, \"在测试集中的准确率\":acc}\n","print(nomraml_dict)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"KjmyQ1yzscCB"},"source":["# 寻找合适的超参数\n","\n","综上，已经完成了模型的建立，并且对最原始的情况进行了记录，下面开始寻找合适的增强的方法。"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1168,"status":"ok","timestamp":1692719017099,"user":{"displayName":"Rose Zhao","userId":"00366990984783742567"},"user_tz":-480},"id":"9HSrrGLCsamB"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","from torchvision.transforms import ToTensor\n","import torch.optim as optim\n","import torchvision\n","import torchvision.transforms as transforms\n","import torch.nn.functional as F\n","from torch.utils.tensorboard import SummaryWriter\n","from get_rank_gpu import get_Effective_Ranks_GPU\n","\n","def get_scale(scale):\n","\n","  # ------------------------------------训练开始前的基本设置， 并得到协方差---------------------------------------------------\n","  # 设置设备\n","  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","  # 添加tensorboard\n","  writer = SummaryWriter(\"logs_train_scale=(0.8, 1.0)\")\n","\n","  # 数据预处理\n","  CIFAR_MEAN = [0.49139968, 0.48215827, 0.44653124]\n","  CIFAR_STD = [0.2023, 0.1994, 0.2010]\n","  train_transform = transforms.Compose([\n","        transforms.RandomResizedCrop(size=(32, 32), scale=(scale, scale)),  # 随机裁剪，但保持大小不变\n","        transforms.ToTensor(),\n","        transforms.Normalize(CIFAR_MEAN, CIFAR_STD)\n","      ])\n","\n","  # 加载 CIFAR-10 数据集， 使用get_Effective_Ranks_GPU，同时计算协方差\n","  get_cifar10_gpu_normal = get_Effective_Ranks_GPU(dataset_name='CIFAR10', path_to_dataset_folder='dataset_folder', my_transform=train_transform)\n","  train_loader = get_cifar10_gpu_normal.build_dataloader()[0]\n","  val_loader = get_cifar10_gpu_normal.build_dataloader()[1]\n","  test_loader = get_cifar10_gpu_normal.build_dataloader()[2]\n","\n","  # 得到对应的协方差\n","  rk, Rk = get_cifar10_gpu_normal.train_rk, get_cifar10_gpu_normal.train_Rk\n","  rk_max_value = max(rk)  # 找到列表中的最大值\n","  rk_max_index = rk.index(rk_max_value)  # 找到最大值对应的索引\n","  Rk_max_value = max(Rk)  # 找到列表中的最大值\n","  Rk_max_index = Rk.index(Rk_max_value)  # 找到最大值对应的索引\n","  # 暂定的超参数\n","  momentum = 0.9\n","  weight_decay = 0.0005\n","  learning_rate = 0.01\n","  batch_size = 512\n","  num_epochs = 5\n","\n","  # 创建模型实例并将其移至 GPU\n","  channel=3\n","  num_classes=10\n","  im_size=(32, 32)\n","  model = MLP()\n","  model.to(device)\n","\n","  # 定义损失函数和优化器\n","  criterion = nn.CrossEntropyLoss()\n","  optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum, weight_decay=weight_decay)\n","\n","  # 记录训练的次数\n","  total_train_step = 0\n","  # 记录训练过程中的准确率\n","  correct = 0\n","  total = 0\n","\n","  # --------------------------------------------开始训练-------------------------------------------\n","  # 训练循环\n","  for epoch in range(num_epochs):\n","      # print(\"------------第{}轮训练开始了-----------\".format(epoch + 1))\n","\n","      # 训练步骤开始\n","      for batch_idx, (imgs, targets) in enumerate(train_loader):\n","        # 将数据移至 GPU\n","          imgs, targets = imgs.to(device), targets.to(device)\n","          # imgs: 一个形状为 (batch_size, channels, height, width) 的张量\n","          # targets: 一个形状为 (batch_size,) 的张量，包含每张图像的标签\n","\n","          outputs = model(imgs)\n","          loss = criterion(outputs, targets)\n","\n","          # 计算准确率\n","          _, predicted = torch.max(outputs, 1)\n","          total += targets.size(0)\n","          correct += (predicted == targets).sum().item()\n","\n","          optimizer.zero_grad()\n","          loss.backward()\n","          optimizer.step()\n","\n","          total_train_step = epoch * len(train_loader) + batch_idx + 1\n","          if total_train_step % 100 == 0:\n","              acc = correct / total\n","              # print(\"训练次数{}时，损失值是{}，准确率是{:.2f}%\".format(total_train_step, loss, acc * 100))\n","              writer.add_scalar(\"train_loss\", loss.item(), total_train_step)\n","              writer.add_scalar(\"train_accuracy\", acc, total_train_step)\n","      # 更新模型权重并记录到Tensorboard\n","      for name, param in model.named_parameters():\n","          writer.add_histogram(name, param.clone().cpu().data.numpy(), epoch)\n","\n","  print(\"Training finished.\")\n","  writer.close()     #将event log写完之后，记得close()\n","  # 在训练循环结束后\n","  # 保存模型参数\n","  filename = \"model_scale={}.pth\".format(scale)\n","  torch.save(model.state_dict(), filename)\n","  print(\"模型参数已保存为{}\".format(filename))\n","\n","  # ---------------------------------------------训练结束，开始验证----------------------------------------------------\n","\n","  # 验证步骤开始\n","  for batch_idx, (imgs, targets) in enumerate(val_loader):\n","    # 将数据移至 GPU\n","      imgs, targets = imgs.to(device), targets.to(device)\n","      # imgs: 一个形状为 (batch_size, channels, height, width) 的张量\n","      # targets: 一个形状为 (batch_size,) 的张量，包含每张图像的标签\n","\n","      outputs = model(imgs)\n","      loss = criterion(outputs, targets)\n","\n","      # 计算准确率\n","      _, predicted = torch.max(outputs, 1)\n","      total += targets.size(0)\n","      correct += (predicted == targets).sum().item()\n","\n","      total_train_step = batch_idx + 1\n","      if total_train_step % 100 == 0:\n","          acc = correct / total\n","          # print(\"测试第{}图片时，损失值是{}，准确率是{:.2f}%\".format(total_train_step, loss, acc * 100))\n","          writer.add_scalar(\"val_loss\", loss.item(), total_train_step)\n","          writer.add_scalar(\"val_accuracy\", acc, total_train_step)\n","  print(\"Valing finished.\")\n","\n","  # ------------------------------------------完成各种工作，记录结果------------------------------------\n","  nomraml_dict = {\"协方差最大值\":rk_max_value, \"协方差最大值对应的索引\":rk_max_index, \"训练的模型的保留路径\":filename,\"在测试集中的损失\":loss, \"在测试集中的准确率\":acc}\n","  print(nomraml_dict)\n","  return nomraml_dict\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5517096,"status":"ok","timestamp":1692724651506,"user":{"displayName":"Rose Zhao","userId":"00366990984783742567"},"user_tz":-480},"id":"Qkc_Dsmm3dnB","outputId":"3414b5a1-2208-43e4-947f-8ae679349282"},"outputs":[],"source":["# 定义初始的scale范围\n","scale_min = 0.1\n","scale_max = 0.9\n","scale_list = [round(x * 0.1, 1) for x in range(int(scale_min * 10), int(scale_max * 10) + 1)]\n","# print(scale_list)\n","dic = {}\n","for scale in scale_list:\n","  print(\"开始scale={}的情况\".format(scale), \"\\n\")\n","  dic['sacle={}'.format(scale)] = get_scale(scale=scale)\n","\n","print(dic)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyP9fiDgS/PdZhfUY4VWlgEu","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.3"}},"nbformat":4,"nbformat_minor":0}
