{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 计算函数的时间和空间消耗"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 准备函数"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义一个计算时间-空间的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil\n",
    "import time\n",
    "import tracemalloc\n",
    "\n",
    "\n",
    "def compute_peak_memory(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        tracemalloc.start()\n",
    "\n",
    "        start_time = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        end_time = time.time()\n",
    "\n",
    "        _, peak_memory = tracemalloc.get_traced_memory()\n",
    "\n",
    "        tracemalloc.stop()\n",
    "\n",
    "        execution_time = end_time - start_time\n",
    "        print(f\"Function {func.__name__} took {execution_time} seconds to execute.\")\n",
    "        print(f\"Peak memory usage: {peak_memory} bytes.\")\n",
    "        return execution_time, peak_memory\n",
    "\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function get_TDA took 346.20754075050354 seconds to execute.\n",
      "Peak memory usage: 1306323257 bytes.\n",
      "torch.Size([3072, 5000]) torch.float32\n",
      "(3072, 3072) float64\n",
      "torch.Size([3072, 5000]) torch.float32\n",
      "(3072, 3072) float64\n",
      "torch.Size([3072, 5000]) torch.float32\n",
      "(3072, 3072) float64\n",
      "torch.Size([3072, 5000]) torch.float32\n",
      "(3072, 3072) float64\n",
      "torch.Size([3072, 5000]) torch.float32\n",
      "(3072, 3072) float64\n",
      "torch.Size([3072, 5000]) torch.float32\n",
      "(3072, 3072) float64\n",
      "torch.Size([3072, 5000]) torch.float32\n",
      "(3072, 3072) float64\n",
      "torch.Size([3072, 5000]) torch.float32\n",
      "(3072, 3072) float64\n",
      "torch.Size([3072, 5000]) torch.float32\n",
      "(3072, 3072) float64\n",
      "torch.Size([3072, 5000]) torch.float32\n",
      "(3072, 3072) float64\n",
      "Function get_BOF took 40.64404559135437 seconds to execute.\n",
      "Peak memory usage: 274284778 bytes.\n",
      "时间的比较：8.518038391929846\n",
      "空间比较：4.762653131994076\n"
     ]
    }
   ],
   "source": [
    "# 示例用法\n",
    "from ripser import ripser\n",
    "from BOF.get_rank_from_matrix import Effective_Ranks\n",
    "@compute_peak_memory\n",
    "def get_TDA(tensor_list:list = []):\n",
    "\n",
    "    # 现在tensor_list里面有5000个符合高斯分布的张量，每个张量形状为(5000, 32*32*3)\n",
    "    \n",
    "    results = []\n",
    "\n",
    "    for image_matrix in tensor_list:\n",
    "        TDA = ripser(X=image_matrix, maxdim=1)\n",
    "        results.append(TDA['dgms'])\n",
    "\n",
    "    return results\n",
    "\n",
    "@compute_peak_memory\n",
    "def get_BOF(tensor_list:list = []):\n",
    "    # 现在tensor_list里面有5000个符合高斯分布的张量，每个张量形状为(5000, 32*32*3)\n",
    "        \n",
    "\n",
    "    results = []\n",
    "    for image_matrix in tensor_list:\n",
    "        # 检查张量形状\n",
    "        if image_matrix.size(0) > image_matrix.size(1):\n",
    "            image_matrix = image_matrix.T  # 如果 m > n，执行转置操作\n",
    "        \n",
    "        get_rank = Effective_Ranks(image_matrix)\n",
    "        r0 = get_rank.r0\n",
    "        R0 = get_rank.R0\n",
    "        rk_max_index = get_rank.rk_max_index\n",
    "        rk_max = get_rank.rk_max_value\n",
    "        Rk_max = get_rank.Rk_value_max_rk_index\n",
    "\n",
    "        results.append({\"isic\": {\"r0\": r0, \"R0\": R0, \"rk_max_index\": rk_max_index, \"rk_max\": rk_max, \"Rk_max\": Rk_max}})\n",
    "    \n",
    "    return results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # my_function()\n",
    "    import torch\n",
    "    # 创建一个空列表用于存放张量\n",
    "    tensor_list = []\n",
    "\n",
    "    # 定义张量形状\n",
    "    tensor_shape = (5000, 32*32*3)\n",
    "    # 生成5000个符合高斯分布的张量并添加到列表中\n",
    "    for _ in range(10):\n",
    "        # 使用torch.randn生成符合标准正态分布的张量\n",
    "        tensor = torch.randn(tensor_shape)\n",
    "        tensor_list.append(tensor)\n",
    "        \n",
    "    TDA_time, TDA_space = get_TDA(tensor_list)\n",
    "    BOF_time, BOF_space = get_BOF(tensor_list)\n",
    "\n",
    "    print('时间的比较：{}'.format(TDA_time / BOF_time))\n",
    "    print('空间比较：{}'.format(TDA_space / BOF_space))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 计算模型参数"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义一个计算参数数量的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(models):\n",
    "    parameters_count = []\n",
    "\n",
    "    for model in models:\n",
    "        # print(type(model).__name__)\n",
    "        parameters_count.append(sum(p.numel() for p in model.parameters()))\n",
    "\n",
    "    return parameters_count"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 计算新ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1707274, 136886, 11173962, 21282122, 23520842, 42512970, 58156618]\n"
     ]
    }
   ],
   "source": [
    "from nets.resnet import ResNet18, ResNet34, ResNet50, ResNet101, ResNet152\n",
    "from nets.simple_net import MLP, LeNet\n",
    "\n",
    "model_list = [MLP(), LeNet(), ResNet18(), ResNet34(), ResNet50(), ResNet101(), ResNet152()]\n",
    "\n",
    "para_list = count_parameters(model_list)\n",
    "print(para_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 计算旧ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1707274, 136886, 11173962, 21282122, 21282122, 41353546, 57883978]\n"
     ]
    }
   ],
   "source": [
    "from nets.simple_net import ResNet18, ResNet34, ResNet50, ResNet101, ResNet152\n",
    "from nets.simple_net import MLP, LeNet\n",
    "\n",
    "model_list = [MLP(), LeNet(), ResNet18(), ResNet34(), ResNet50(), ResNet101(), ResNet152()]\n",
    "\n",
    "para_list = count_parameters(model_list)\n",
    "print(para_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorchGpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
